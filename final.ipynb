{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import xgboost as xgb\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 데이터 불러오기\n",
    "file_path = './rainfall_train.csv'\n",
    "rainfall_train = pd.read_csv(file_path)\n",
    "# rainfall_train.vv 열이 음수인 경우 해당 행 제거\n",
    "rainfall_train = rainfall_train[rainfall_train['rainfall_train.vv'] >= 0]\n",
    "# 연도, 월, 일, 시간 칼럼을 하나의 datetime 칼럼으로 결합 및 변환\n",
    "year_mapping = {'A': 2001, 'B': 2002, 'C': 2003, 'D': 2004}\n",
    "rainfall_train['rainfall_train.fc_year'] = rainfall_train['rainfall_train.fc_year'].map(year_mapping)\n",
    "rainfall_train['rainfall_train.ef_year'] = rainfall_train['rainfall_train.ef_year'].map(year_mapping)\n",
    "\n",
    "rainfall_train['rainfall_train.fc_datetime'] = pd.to_datetime(rainfall_train[['rainfall_train.fc_year', 'rainfall_train.fc_month', 'rainfall_train.fc_day', 'rainfall_train.fc_hour']].astype(str).agg('-'.join, axis=1), format='%Y-%m-%d-%H')\n",
    "rainfall_train['rainfall_train.ef_datetime'] = pd.to_datetime(rainfall_train[['rainfall_train.ef_year', 'rainfall_train.ef_month', 'rainfall_train.ef_day', 'rainfall_train.ef_hour']].astype(str).agg('-'.join, axis=1), format='%Y-%m-%d-%H')\n",
    "\n",
    "# 필요 없는 칼럼 제거\n",
    "rainfall_train.drop(columns=['rainfall_train.fc_year', 'rainfall_train.fc_month', 'rainfall_train.fc_day', 'rainfall_train.fc_hour'], inplace=True)\n",
    "rainfall_train.drop(columns=['rainfall_train.ef_year', 'rainfall_train.ef_month', 'rainfall_train.ef_day', 'rainfall_train.ef_hour'], inplace=True)\n",
    "\n",
    "# 구간 확률 계산\n",
    "rainfall_train['prob_0'] = 100 - rainfall_train['rainfall_train.v01']\n",
    "rainfall_train['prob_1'] = rainfall_train['rainfall_train.v01'] - rainfall_train['rainfall_train.v02']\n",
    "rainfall_train['prob_2'] = rainfall_train['rainfall_train.v02'] - rainfall_train['rainfall_train.v03']\n",
    "rainfall_train['prob_3'] = rainfall_train['rainfall_train.v03'] - rainfall_train['rainfall_train.v04']\n",
    "rainfall_train['prob_4'] = rainfall_train['rainfall_train.v04'] - rainfall_train['rainfall_train.v05']\n",
    "rainfall_train['prob_5'] = rainfall_train['rainfall_train.v05'] - rainfall_train['rainfall_train.v06']\n",
    "rainfall_train['prob_6'] = rainfall_train['rainfall_train.v06'] - rainfall_train['rainfall_train.v07']\n",
    "rainfall_train['prob_7'] = rainfall_train['rainfall_train.v07'] - rainfall_train['rainfall_train.v08']\n",
    "rainfall_train['prob_8'] = rainfall_train['rainfall_train.v08'] - rainfall_train['rainfall_train.v09']\n",
    "rainfall_train['prob_9'] = rainfall_train['rainfall_train.v09']\n",
    "\n",
    "rainfall_train[\"expected\"] = (rainfall_train[\"prob_0\"] * 0\n",
    "                + rainfall_train[\"prob_1\"] * 10\n",
    "                + rainfall_train[\"prob_2\"] * 20\n",
    "                + rainfall_train[\"prob_3\"] * 30\n",
    "                + rainfall_train[\"prob_4\"] * 40\n",
    "                + rainfall_train[\"prob_5\"] * 50\n",
    "                + rainfall_train[\"prob_6\"] * 60\n",
    "                + rainfall_train[\"prob_7\"] * 70\n",
    "                + rainfall_train[\"prob_8\"] * 80\n",
    "                + rainfall_train[\"prob_9\"] * 90) / 100\n",
    "\n",
    "rainfall_train.drop(columns=[\"prob_0\",\"prob_1\",\"prob_2\",\"prob_3\",\"prob_4\",\"prob_5\",\"prob_6\",\"prob_7\",\"prob_8\",\"prob_9\"], inplace=True)\n",
    "\n",
    "# datetime 정보를 유용한 특성으로 변환\n",
    "rainfall_train['fc_year'] = rainfall_train['rainfall_train.fc_datetime'].dt.year\n",
    "rainfall_train['fc_month'] = rainfall_train['rainfall_train.fc_datetime'].dt.month\n",
    "rainfall_train['fc_day'] = rainfall_train['rainfall_train.fc_datetime'].dt.day\n",
    "rainfall_train['fc_hour'] = rainfall_train['rainfall_train.fc_datetime'].dt.hour\n",
    "\n",
    "rainfall_train['ef_year'] = rainfall_train['rainfall_train.ef_datetime'].dt.year\n",
    "rainfall_train['ef_month'] = rainfall_train['rainfall_train.ef_datetime'].dt.month\n",
    "rainfall_train['ef_day'] = rainfall_train['rainfall_train.ef_datetime'].dt.day\n",
    "rainfall_train['ef_hour'] = rainfall_train['rainfall_train.ef_datetime'].dt.hour\n",
    "\n",
    "rainfall_train.drop(columns=['rainfall_train.fc_datetime', 'rainfall_train.ef_datetime'], inplace=True)\n",
    "\n",
    "# 범주형 변수를 원-핫 인코딩\n",
    "rainfall_train = pd.get_dummies(rainfall_train, columns=['rainfall_train.stn4contest'], drop_first=True)\n",
    "\n",
    "# 계절 정보 추가\n",
    "def get_season(month):\n",
    "    if month in [5, 6]:\n",
    "        return '1'\n",
    "    elif month in [7, 8]:\n",
    "        return '2'\n",
    "    else:\n",
    "        return '3'\n",
    "\n",
    "rainfall_train['season'] = rainfall_train['fc_month'].apply(get_season)\n",
    "\n",
    "# 계절별 데이터프레임 생성\n",
    "df_1 = rainfall_train[rainfall_train['season'] == '1'].reset_index(drop=True)\n",
    "df_2 = rainfall_train[rainfall_train['season'] == '2'].reset_index(drop=True)\n",
    "df_3 = rainfall_train[rainfall_train['season'] == '3'].reset_index(drop=True)\n",
    "\n",
    "# -999 값을 가진 행 제거\n",
    "rainfall_train = rainfall_train[rainfall_train['rainfall_train.class_interval'] != -999]\n",
    "\n",
    "# 특성 및 레이블 설정\n",
    "X = rainfall_train.drop(columns=['Unnamed: 0','rainfall_train.class_interval','rainfall_train.v01','rainfall_train.v02', 'rainfall_train.v03', 'rainfall_train.v04', 'rainfall_train.v05','rainfall_train.v06', 'rainfall_train.v07','rainfall_train.v08', 'rainfall_train.v09','rainfall_train.vv'])\n",
    "y = rainfall_train['rainfall_train.class_interval']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m12828/12828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4ms/step - loss: 1.6951 - val_loss: 1.2865\n",
      "Epoch 2/10\n",
      "\u001b[1m12828/12828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4ms/step - loss: 1.2505 - val_loss: 1.1182\n",
      "Epoch 3/10\n",
      "\u001b[1m12828/12828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4ms/step - loss: 1.0817 - val_loss: 0.9835\n",
      "Epoch 4/10\n",
      "\u001b[1m12828/12828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4ms/step - loss: 0.9546 - val_loss: 0.8906\n",
      "Epoch 5/10\n",
      "\u001b[1m12828/12828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4ms/step - loss: 0.8698 - val_loss: 0.8406\n",
      "Epoch 6/10\n",
      "\u001b[1m12828/12828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4ms/step - loss: 0.7887 - val_loss: 0.7843\n",
      "Epoch 7/10\n",
      "\u001b[1m12828/12828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4ms/step - loss: 0.7433 - val_loss: 0.7396\n",
      "Epoch 8/10\n",
      "\u001b[1m12828/12828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 4ms/step - loss: 0.6879 - val_loss: 0.6940\n",
      "Epoch 9/10\n",
      "\u001b[1m12828/12828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 4ms/step - loss: 0.6467 - val_loss: 0.6732\n",
      "Epoch 10/10\n",
      "\u001b[1m12828/12828\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 4ms/step - loss: 0.6090 - val_loss: 0.6440\n",
      "\u001b[1m3564/3564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m13333/13333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4ms/step - loss: 3.4360 - val_loss: 2.8249\n",
      "Epoch 2/10\n",
      "\u001b[1m13333/13333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 4ms/step - loss: 2.7484 - val_loss: 2.5224\n",
      "Epoch 3/10\n",
      "\u001b[1m13333/13333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 4ms/step - loss: 2.4014 - val_loss: 2.2645\n",
      "Epoch 4/10\n",
      "\u001b[1m13333/13333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4ms/step - loss: 2.1834 - val_loss: 2.0880\n",
      "Epoch 5/10\n",
      "\u001b[1m13333/13333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 4ms/step - loss: 1.9976 - val_loss: 1.9568\n",
      "Epoch 6/10\n",
      "\u001b[1m13333/13333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4ms/step - loss: 1.8541 - val_loss: 1.8652\n",
      "Epoch 7/10\n",
      "\u001b[1m13333/13333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 4ms/step - loss: 1.7563 - val_loss: 1.7619\n",
      "Epoch 8/10\n",
      "\u001b[1m13333/13333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4ms/step - loss: 1.6470 - val_loss: 1.6612\n",
      "Epoch 9/10\n",
      "\u001b[1m13333/13333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 5ms/step - loss: 1.5773 - val_loss: 1.6296\n",
      "Epoch 10/10\n",
      "\u001b[1m13333/13333\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 5ms/step - loss: 1.5097 - val_loss: 1.5862\n",
      "\u001b[1m3704/3704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m6437/6437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 6ms/step - loss: 1.4557 - val_loss: 1.1972\n",
      "Epoch 2/10\n",
      "\u001b[1m6437/6437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 6ms/step - loss: 1.0900 - val_loss: 1.0427\n",
      "Epoch 3/10\n",
      "\u001b[1m6437/6437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - loss: 0.9341 - val_loss: 0.9247\n",
      "Epoch 4/10\n",
      "\u001b[1m6437/6437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 5ms/step - loss: 0.8404 - val_loss: 0.8393\n",
      "Epoch 5/10\n",
      "\u001b[1m6437/6437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - loss: 0.7554 - val_loss: 0.7988\n",
      "Epoch 6/10\n",
      "\u001b[1m6437/6437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - loss: 0.6923 - val_loss: 0.7808\n",
      "Epoch 7/10\n",
      "\u001b[1m6437/6437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.6463 - val_loss: 0.7394\n",
      "Epoch 8/10\n",
      "\u001b[1m6437/6437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step - loss: 0.6049 - val_loss: 0.7029\n",
      "Epoch 9/10\n",
      "\u001b[1m6437/6437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5ms/step - loss: 0.5692 - val_loss: 0.6815\n",
      "Epoch 10/10\n",
      "\u001b[1m6437/6437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 5ms/step - loss: 0.5488 - val_loss: 0.6428\n",
      "\u001b[1m1788/1788\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "def train_lstm_model(df):\n",
    "    # 특성 및 레이블 설정\n",
    "    X = df.drop(columns=['Unnamed: 0', 'rainfall_train.v01','rainfall_train.v02', 'rainfall_train.v03','rainfall_train.v04','rainfall_train.v05','rainfall_train.v06','rainfall_train.v07', 'rainfall_train.v08', 'rainfall_train.v09', 'rainfall_train.class_interval','rainfall_train.vv', 'season'])\n",
    "    y = df['rainfall_train.class_interval']\n",
    "\n",
    "    # 특성 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # y 인덱스 재설정\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # LSTM을 위한 시계열 데이터 형태로 변환\n",
    "    def create_sequences(X, y, time_steps=1):\n",
    "        Xs, ys = [], []\n",
    "        for i in range(len(X) - time_steps):\n",
    "            Xs.append(X[i:(i + time_steps)])\n",
    "            ys.append(y[i + time_steps])\n",
    "        return np.array(Xs), np.array(ys)\n",
    "\n",
    "    time_steps = 10\n",
    "    X_lstm, y_lstm = create_sequences(X_scaled, y, time_steps)\n",
    "\n",
    "    # 데이터 분할\n",
    "    X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X_lstm, y_lstm, test_size=0.2, random_state=42)\n",
    "\n",
    "    # LSTM 모델 정의\n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(LSTM(units=50, return_sequences=True, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])))\n",
    "    model_lstm.add(LSTM(units=50, return_sequences=False))\n",
    "    model_lstm.add(Dropout(0.2))\n",
    "    model_lstm.add(Dense(units=1))\n",
    "    model_lstm.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # LSTM 모델 훈련\n",
    "    model_lstm.fit(X_train_lstm, y_train_lstm, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "    # 예측\n",
    "    y_pred_lstm = model_lstm.predict(X_test_lstm)\n",
    "    y_pred_lstm = np.round(y_pred_lstm).astype(int).flatten()\n",
    "\n",
    "    # 결과 저장\n",
    "    result_df = df.iloc[time_steps:len(y_pred_lstm) + time_steps].copy()\n",
    "    result_df = result_df.iloc[:len(y_pred_lstm)]\n",
    "    result_df['estimated_rank'] = y_pred_lstm\n",
    "\n",
    "    return result_df\n",
    "\n",
    "# 각 계절별로 모델 학습 및 예측\n",
    "predictions_1 = train_lstm_model(df_1)\n",
    "predictions_2 = train_lstm_model(df_2)\n",
    "predictions_3 = train_lstm_model(df_3)\n",
    "\n",
    "# 계절별 예측 결과 병합\n",
    "final_predictions_df = pd.concat([predictions_1, predictions_2, predictions_3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Model Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96     48055\n",
      "           1       0.71      0.45      0.55      1020\n",
      "           2       0.64      0.47      0.54      1510\n",
      "           3       0.65      0.45      0.53      1391\n",
      "           4       0.59      0.46      0.52      1400\n",
      "           5       0.63      0.52      0.57      1831\n",
      "           6       0.68      0.50      0.58      1383\n",
      "           7       0.72      0.56      0.63       792\n",
      "           8       0.85      0.67      0.75       312\n",
      "           9       0.86      0.83      0.85       256\n",
      "\n",
      "    accuracy                           0.90     57950\n",
      "   macro avg       0.73      0.59      0.65     57950\n",
      "weighted avg       0.89      0.90      0.89     57950\n",
      "\n",
      "[[47174   128   185   148   148   130    79    36    17    10]\n",
      " [  458   463    40    10    16    23     5     1     0     4]\n",
      " [  636    28   705    31    44    41    17     7     0     1]\n",
      " [  529    13    45   619    65    74    32    12     2     0]\n",
      " [  536     3    38    45   647    84    31    13     1     2]\n",
      " [  529     9    51    52    97   956    86    43     5     3]\n",
      " [  374    10    32    28    63   129   695    48     3     1]\n",
      " [  169     0    11     9    20    58    67   446     7     5]\n",
      " [   61     0     1     3     5     9    12     4   208     9]\n",
      " [   20     1     0     1     0     9     3     6     3   213]]\n",
      "CSI: 0.45953971789161097\n",
      "H: 4952, F: 2512, M: 3312, C: 47174\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 스태킹 모델 적용\n",
    "def train_stacking_model(final_df):\n",
    "    # 특성 및 레이블 설정\n",
    "    X = final_df.drop(columns=['Unnamed: 0', 'rainfall_train.v01','rainfall_train.v02', 'rainfall_train.v03','rainfall_train.v04','rainfall_train.v05','rainfall_train.v06','rainfall_train.v07', 'rainfall_train.v08', 'rainfall_train.v09','rainfall_train.vv', 'rainfall_train.class_interval', 'estimated_rank'])\n",
    "    y = final_df['rainfall_train.class_interval']\n",
    "\n",
    "    # 특성 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # LSTM 모델 예측 추가\n",
    "    lstm_predictions = final_df['estimated_rank']\n",
    "\n",
    "    # XGBoost 모델 훈련 및 예측\n",
    "    model_xgb = xgb.XGBClassifier(objective='multi:softmax', num_class=10)\n",
    "    X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    model_xgb.fit(X_train_xgb, y_train_xgb)\n",
    "    xgb_predictions = model_xgb.predict(X_test_xgb)\n",
    "\n",
    "    # 새로운 훈련 및 테스트 데이터 생성 (원래 특성 + 모델 예측)\n",
    "    X_train_stack = np.column_stack((X_train_xgb, lstm_predictions[:len(X_train_xgb)]))\n",
    "    X_test_stack = np.column_stack((X_test_xgb, lstm_predictions[len(X_train_xgb):]))\n",
    "\n",
    "    # 스태킹 모델 정의\n",
    "    estimators = [\n",
    "        ('xgb', model_xgb),\n",
    "        ('lstm', LogisticRegression())  # LSTM 예측을 Logistic Regression으로 대체\n",
    "    ]\n",
    "\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=LogisticRegression()\n",
    "    )\n",
    "\n",
    "    # 스태킹 모델 훈련\n",
    "    stacking_model.fit(X_train_stack, y_train_xgb)\n",
    "\n",
    "    # 예측\n",
    "    y_pred_stack = stacking_model.predict(X_test_stack)\n",
    "\n",
    "    # 평가\n",
    "    print(\"Stacking Model Performance:\")\n",
    "    print(classification_report(y_test_xgb, y_pred_stack))\n",
    "    print(confusion_matrix(y_test_xgb, y_pred_stack))\n",
    "\n",
    "    # 최종 예측 결과를 데이터프레임에 추가\n",
    "    results_df = pd.DataFrame({'estimated_rank': y_pred_stack, 'rainfall_train.class_interval': y_test_xgb})\n",
    "\n",
    "    # H, F, M, C 계산 함수\n",
    "    def calculate_csi_components(df):\n",
    "        H = ((df['estimated_rank'] != 0) & (df['rainfall_train.class_interval'] != 0) & (df['estimated_rank'] == df['rainfall_train.class_interval'])).sum()\n",
    "        F = ((df['estimated_rank'] != 0) & (df['estimated_rank'] != df['rainfall_train.class_interval'])).sum()\n",
    "        M = ((df['estimated_rank'] == 0) & (df['rainfall_train.class_interval'] != 0)).sum()\n",
    "        C = ((df['estimated_rank'] == 0) & (df['rainfall_train.class_interval'] == 0)).sum()\n",
    "        return H, F, M, C\n",
    "\n",
    "    # CSI 계산 함수\n",
    "    def calculate_csi(H, F, M):\n",
    "        return H / (H + F + M) if (H + F + M) > 0 else 0\n",
    "\n",
    "    # H, F, M, C 계산\n",
    "    H, F, M, C = calculate_csi_components(results_df)\n",
    "\n",
    "    # CSI 계산\n",
    "    csi_value = calculate_csi(H, F, M)\n",
    "    print(f\"CSI: {csi_value}\")\n",
    "    print(f\"H: {H}, F: {F}, M: {M}, C: {C}\")\n",
    "\n",
    "    # H, F, M, C 값 시각화\n",
    "    metrics = pd.DataFrame({'Metric': ['H', 'F', 'M', 'C'], 'Count': [H, F, M, C]})\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Metric', y='Count', data=metrics, palette='viridis')\n",
    "    plt.title('H, F, M, C Counts')\n",
    "    plt.xlabel('Metric')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "# 스태킹 모델 학습 및 평가\n",
    "train_stacking_model(final_predictions_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
